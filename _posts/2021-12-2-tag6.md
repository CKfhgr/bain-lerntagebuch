---
title: Tag 6 - Metadaten modellieren und Schnittstellen nutzen
date: 2021-12-02
---

Liebes Lerntagebuch

Wir erhielten zuerst einen kurzen Throwback zur letzten Lerneinheit bzw. einen erneuten Überblick zum Schaubbild und wo wir uns aktuell befanden.
Danach bekammen wir eine kurze Einführung in die Theorie zu den Austauschprotokollen für Metadaten "ZR39.50", "SRU" und "OAI-PMH", wobei letzteres sehr weit verbreitet ist und für tägliche Aktualisierungen von Daten geeignet ist.

Danach gingen wir ins Praktische über. Das Ziel war, die Metadaten über die OAI-PMH Schnittstelle zu harvesten mittels des Tools VuFindHarvest.
Zuerst mussten wir aber noch sicherstellen, dass unsere Daten aus den früheren Übungen zu Koha und Archivesspaces auch vorhanden waren, also unsere "OAI-PMH" Endpoints überhaupt erreichbar sind. Dazu rief ich im Firefos Browser meiner Virtuellen Maschine einmal für Koha die URL "http://bibliothek.meine-schule.org/cgi-bin/koha/oai.pl" auf und für Archivesspaces "http://localhost:8082". Ersteres funktionierte auf Anhieb, für Archivesspaces musste ich jedoch den Dienst mittels Commandline-Befehl "archivesspace/archivesspace.sh" neustarten. Danach war auch der Zugriff auf Archivesspaces sichergestellt.

Danach musste  noch VuFindHarvest 4.1.0 installiert werden. Da VuFindHarvest ein PHP-basierendes Programm ist, wurde zusätzlich "composer" installiert. Composer ist ein ein Tool, mit welchem Entwickler externe Pakete oder Bibliotheken verwalten und in ihre PHP-basierten Projekte integrieren können (1).
Hier hatte ich zu Beginn des Installationsprozesses einer Fehlermeldung, und zwar waren teils installierte Pakete von mir fehlerhaft. Die Fehlermeldung kam bereits beim Befehl "*sudo apt update*", weshalb ich mich hier entschloss mal schnell den Befehl "*apt --fix-broken install*" auszuführen um hier wieder alles zu korrigieren. 
![screenshot_bain1](https://user-images.githubusercontent.com/85638168/147661128-e7ed206c-69e0-4913-8c3c-33cd67353d03.png)

Dies funktionierte zum Glück auf Anhieb und ich konnte die Installation von VuFindHarverst und Composer abschliessen.
![screenshot_bain2](https://user-images.githubusercontent.com/85638168/147661513-586d8148-72cc-43e6-a827-faf0eb85a86e.png)

Dann ging es mit dem Harvesting weiter, also um den "Import" der Daten aus Koha und Archivesspaces. Zuerst wurde dieser für Koha vollzogen, danach für Archivesspaces. Bei beiden war der Commandline Befehl der gleiche, nur der Pfad, das Format und der Zielort musste angepasst werden. Am Beispiel Koha hier ersichtlich:
![2021-12-29 13_52_39-Greenshot Editor](https://user-images.githubusercontent.com/85638168/147664710-53935e9f-6e8a-4096-b080-61a2d54c8658.png)

Für beide Endpoints hatte ich keine Fehlermeldungen, bei beiden funktionierte das Harvesting direkt.
![screenshot_bain3](https://user-images.githubusercontent.com/85638168/147665322-ce22a6e7-4f20-48bf-b2f0-cafeb2eef79e.png)

Da ich meine Daten aus der letzten Übung zu DSpace nicht hatte, nutze ich die zur Verfügung gestellten Beispieldaten für die Umsetzung des Harvesting mit den DSpace-Daten.

Danach gingen wir zum neuen Thema "**XSLT Crosswalks mit MarcEdit**" über, das heisst wir musste alle unsere vorliegenden Format in MARCXML konvertieren. Dafür mussten wir MarcEdit 7 installieren. Die Software installierte ich nach Anleitung der Dozenten und konnte diese erfolgreich nach Installation starten.



(1) https://www.hostinger.com/tutorials/how-to-install-composer
